"""
éŸ³é¢‘è§†é¢‘è¯­éŸ³è½¬æ–‡å­—
1. å¯å¤„ç†æ–‡ä»¶/æ–‡ä»¶å¤¹é€’å½’æ‰€æœ‰æ–‡ä»¶
2. éŸ³é¢‘ç›´æ¥è½¬å½•ï¼Œè§†é¢‘å…ˆè½¬æˆä¸´æ—¶mp3ï¼Œå†è½¬å½•ï¼Œç»“æŸååˆ é™¤ä¸´æ—¶mp3
3. æ”¯æŒ OpenAI Whisper / Faster-Whisper å¼•æ“
4. å¯é€‰ split_segment=Trueï¼Œå¯¹å­—å¹•è¿›è¡Œå¥å­çº§åˆå¹¶ä¸ä¼˜åŒ–
5. å¯è¾“å‡ºSRTï¼ˆå¸¦æ—¶é—´æˆ³å­—å¹•ï¼‰ï¼ŒTXT ï¼ˆçº¯æ–‡å­—ï¼‰
"""
import os
import time
import re
import subprocess
import tempfile

# =====================
# å·¥å…·å‡½æ•°
# =====================

SENT_END_CHARS = set(".?!ã€‚ï¼Ÿï¼")

def format_timestamp(seconds: float) -> str:
    h = int(seconds // 3600)
    m = int((seconds % 3600) // 60)
    s = int(seconds % 60)
    ms = int(round((seconds - int(seconds)) * 1000))
    return f"{h:02}:{m:02}:{s:02},{ms:03}"

def parse_timestamp(ts: str) -> float:
    h, m, rest = ts.split(":")
    s, ms = rest.split(",")
    return int(h)*3600 + int(m)*60 + int(s) + int(ms)/1000

# =====================
# Whisper è½¬å½•
# =====================

def cpu_rest(start_time):
    elapsed_minutes = (time.time() - start_time) / 60
    rest_seconds = (int(elapsed_minutes // 10) + 1) * 60
    print(f"è½¬å½•å®Œæˆï¼Œè€—æ—¶ {elapsed_minutes:.2f} åˆ†é’Ÿï¼Œä¼‘æ¯ {rest_seconds} ç§’ã€‚")
    time.sleep(rest_seconds)

def transcribe_openai_whisper(model, input_path, output_path, language="en", srt_txt="srt"):
    start_time = time.time()
    result = model.transcribe(input_path, language=language)

    srt_path = output_path.replace(".txt", ".srt")
    txt_path = output_path.replace(".txt", ".txt")

    if srt_txt == "srt":
        with open(srt_path, "w", encoding="utf-8") as f:
            for idx, segment in enumerate(result["segments"], start=1):
                f.write(f"{idx}\n{format_timestamp(segment['start'])} --> {format_timestamp(segment['end'])}\n{segment['text'].strip()}\n\n")
        print(f"[OpenAI-Whisper] âœ… {srt_path} ç”¨æ—¶ {(time.time()-start_time)/60:.2f} åˆ†é’Ÿ")
        cpu_rest(start_time)
        return srt_path
    else:  # txt
        with open(txt_path, "w", encoding="utf-8") as f:
            for segment in result["segments"]:
                text = segment['text'].strip()
                if text:  # è¿‡æ»¤ç©ºè¡Œ
                    f.write(text + "\n")
        print(f"[OpenAI-Whisper] âœ… {txt_path} ç”¨æ—¶ {(time.time()-start_time)/60:.2f} åˆ†é’Ÿ")
        cpu_rest(start_time)
        return txt_path
    
def transcribe_faster_whisper(model, input_path, output_path, language="en", srt_txt="srt"):
    start_time = time.time()
    segments, _ = model.transcribe(input_path, beam_size=5, language=language)

    srt_path = output_path.replace(".txt", ".srt")
    txt_path = output_path.replace(".txt", ".txt")

    if srt_txt == "srt":
        with open(srt_path, "w", encoding="utf-8") as f:
            for idx, segment in enumerate(segments, start=1):
                f.write(f"{idx}\n{format_timestamp(segment.start)} --> {format_timestamp(segment.end)}\n{segment.text.strip()}\n\n")
        print(f"[Faster-Whisper] âœ… {srt_path} ç”¨æ—¶ {(time.time()-start_time)/60:.2f} åˆ†é’Ÿ")
        cpu_rest(start_time)
        return srt_path
    else:  # txt
        with open(txt_path, "w", encoding="utf-8") as f:
            for segment in segments:
                text = segment.text.strip()
                if text:  # è¿‡æ»¤ç©ºè¡Œ
                    f.write(text + "\n")
        print(f"[Faster-Whisper] âœ… {txt_path} ç”¨æ—¶ {(time.time()-start_time)/60:.2f} åˆ†é’Ÿ")
        cpu_rest(start_time)
        return txt_path

# =====================
# SRT å¤„ç†
# =====================

def read_srt(path: str):
    with open(path, "r", encoding="utf-8") as f:
        content = f.read().strip()
    blocks = re.split(r"\n\s*\n", content)
    entries = []
    for block in blocks:
        lines = block.strip().splitlines()
        if len(lines) >= 3:
            times = lines[1].split("-->")
            start = parse_timestamp(times[0].strip())
            end = parse_timestamp(times[1].strip())
            text = " ".join(lines[2:]).strip()
            entries.append((start, end, text))
    return entries

def write_srt(entries, path: str):
    with open(path, "w", encoding="utf-8") as f:
        for i, (start, end, text) in enumerate(entries, start=1):
            f.write(f"{i}\n")
            f.write(f"{format_timestamp(start)} --> {format_timestamp(end)}\n")
            f.write(text + "\n\n")

def split_sentence_with_time(start, end, text):
    parts = re.split(r"([.?!ã€‚ï¼Ÿï¼])", text)
    chunks, buffer = [], ""
    for p in parts:
        if not p.strip():
            continue
        buffer += p
        if p in SENT_END_CHARS:
            chunks.append(buffer.strip())
            buffer = ""
    if buffer:
        chunks.append(buffer.strip())

    total_duration = end - start
    total_words = sum(len(c.split()) for c in chunks) or 1
    avg_word_time = total_duration / total_words

    result, cur_start = [], start
    for c in chunks:
        word_count = len(c.split()) or 1
        cur_end = cur_start + word_count * avg_word_time
        result.append((cur_start, cur_end, c))
        cur_start = cur_end
    return result

def merge_sentences(entries):
    merged, cache = [], []
    for start, end, text in entries:
        cache.append((start, end, text))
        if text and text[-1] in SENT_END_CHARS:
            new_start, new_end = cache[0][0], cache[-1][1]
            new_text = " ".join([t for _, _, t in cache])
            merged.extend(split_sentence_with_time(new_start, new_end, new_text))
            cache = []
    if cache:
        new_start, new_end = cache[0][0], cache[-1][1]
        new_text = " ".join([t for _, _, t in cache])
        merged.append((new_start, new_end, new_text))
    return merged

def process_srt(file_path: str):
    entries = read_srt(file_path)
    merged_entries = merge_sentences(entries)

    # ====== æ–°é€»è¾‘ï¼šæŠŠåŸå§‹æ–‡ä»¶ç§»åˆ° original/ å­ç›®å½• ======
    base_dir = os.path.dirname(file_path)
    base_name = os.path.basename(file_path)
    original_dir = os.path.join(base_dir, "original")
    os.makedirs(original_dir, exist_ok=True)

    # ç§»åŠ¨åŸå§‹æ–‡ä»¶
    original_path = os.path.join(original_dir, base_name)
    os.replace(file_path, original_path)

    # æœ€ç»ˆå­—å¹•æ–‡ä»¶ï¼ˆå’Œè§†é¢‘åŒåï¼‰
    output_path = file_path  # ç›´æ¥è¦†ç›–åŸå§‹ä½ç½®
    write_srt(merged_entries, output_path)
# =====================
# ä¸»å…¥å£
# =====================

def extract_audio_temp(input_path: str) -> str:
    """å¦‚æœæ˜¯è§†é¢‘æ–‡ä»¶ï¼Œæå–éŸ³é¢‘åˆ°ä¸´æ—¶ mp3ï¼Œè¿”å›æ–°è·¯å¾„ï¼›å¦åˆ™è¿”å›åŸè·¯å¾„"""
    video_exts = (".mp4", ".mkv", ".avi", ".mov", ".webm")
    if input_path.lower().endswith(video_exts):
        fd, out_path = tempfile.mkstemp(suffix=".mp3")
        os.close(fd)
        print(f"ğŸ¬ æ£€æµ‹åˆ°è§†é¢‘æ–‡ä»¶ï¼Œæå–ä¸´æ—¶éŸ³é¢‘: {out_path}")
        cmd = [
            "ffmpeg", "-y", "-i", input_path,
            "-vn", "-ac", "1", "-ar", "16000", "-b:a", "128k",
            out_path
        ]
        subprocess.run(cmd, check=True)
        return out_path
    return input_path

def cooking(input_path, engine, model_name, device="cpu", language="en", split_segment=False, srt_txt="srt"):
    if engine == "whisper":
        import whisper
        asr_model = whisper.load_model(model_name)
        transcribe_func = transcribe_openai_whisper
    elif engine == "faster_whisper":
        from faster_whisper import WhisperModel
        compute_type = "int8" if device == "cpu" else "float16"
        asr_model = WhisperModel(model_name, device=device, compute_type=compute_type)
        transcribe_func = transcribe_faster_whisper
    else:
        raise ValueError("âŒ engine å¿…é¡»æ˜¯ 'whisper' æˆ– 'faster_whisper'")

    if os.path.isfile(input_path):
        temp_path = extract_audio_temp(input_path)
        try:
            out_path = os.path.splitext(input_path)[0] + ".txt"
            print(f"ğŸ¬ {input_path} å¼€å§‹è½¬å½•...")
            srt_path = transcribe_func(asr_model, temp_path, out_path, language, srt_txt=srt_txt)
            if split_segment and srt_txt == "srt":
                process_srt(srt_path)
        finally:
            if temp_path != input_path and os.path.exists(temp_path):
                os.remove(temp_path)
                print(f"ğŸ—‘ï¸ å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {temp_path}")
    elif os.path.isdir(input_path):
        for f in os.listdir(input_path):
            if f.endswith((".mp3", ".m4a", ".webm", ".mp4", ".mkv", ".avi")):
                in_path = os.path.join(input_path, f)
                temp_path = extract_audio_temp(in_path)
                try:
                    out_path = os.path.splitext(in_path)[0] + ".txt"
                    print(f"ğŸ¬ {f} å¼€å§‹è½¬å½•...")
                    srt_path = transcribe_func(asr_model, temp_path, out_path, language, srt_txt=srt_txt)
                    if split_segment and srt_txt == "srt":
                        process_srt(srt_path)
                finally:
                    if temp_path != in_path and os.path.exists(temp_path):
                        os.remove(temp_path)
                        print(f"ğŸ—‘ï¸ å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {temp_path}")
    else:
        print(f"âŒ æ— æ•ˆè·¯å¾„: {input_path}")


if __name__ == "__main__":
    input_path = "/Users/jiangsai/Downloads/TTT/1 - Introduction to the Course and to Trading.mp4"
    engine = "whisper"    # "whisper" æˆ– "faster_whisper"
    model = "small"       # "tiny" / "base" / "small" / "medium" / "large-v2"
    split_segment = True  # False = ç±»ä¼¼YouTubeé‚£ç§æ®µä¸æˆæ®µçš„å­—å¹• True = æ‹†åˆ†æŒ‰å¥å·åˆå¹¶
    srt_txt = "srt"       # "srt" = è¾“å‡ºå­—å¹•  "txt" = è¾“å‡ºçº¯æ–‡æœ¬
    language="en"
    cooking(input_path, engine, model, device="cpu", language=language, split_segment=split_segment, srt_txt=srt_txt)

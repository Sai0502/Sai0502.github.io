1. æœ‰äº›è§†é¢‘ç”¨faster_whisperè½¬å½•æ•ˆæžœä¸å¥½ï¼Œç›´æŽ¥ä¸Šä¼ YouTubeï¼Œå…¬å¼€èŒƒå›´é€‰ã€ä¸å…¬å¼€åˆ—å‡ºã€‘ï¼Œç„¶åŽä¸‹è½½srtæ–‡ä»¶ï¼Œå†ç”¨ä¸‹è¿°è„šæœ¬å¤„ç†

   ```python
   import re
   import os
   
   SENT_END_CHARS = set(".?!ã€‚ï¼Ÿï¼")
   
   def format_timestamp(seconds: float) -> str:
       h = int(seconds // 3600)
       m = int((seconds % 3600) // 60)
       s = int(seconds % 60)
       ms = int(round((seconds - int(seconds)) * 1000))
       return f"{h:02}:{m:02}:{s:02},{ms:03}"
   
   def parse_timestamp(ts: str) -> float:
       h, m, rest = ts.split(":")
       s, ms = rest.split(",")
       return int(h)*3600 + int(m)*60 + int(s) + int(ms)/1000
   
   def read_srt(path: str):
       with open(path, "r", encoding="utf-8") as f:
           content = f.read().strip()
       blocks = re.split(r"\n\s*\n", content)
       entries = []
       for block in blocks:
           lines = block.strip().splitlines()
           if len(lines) >= 3:
               idx = lines[0].strip()
               times = lines[1].split("-->")
               start = parse_timestamp(times[0].strip())
               end = parse_timestamp(times[1].strip())
               text = " ".join(lines[2:]).strip()
               entries.append((start, end, text))
       return entries
   
   def write_srt(entries, path: str):
       with open(path, "w", encoding="utf-8") as f:
           for i, (start, end, text) in enumerate(entries, start=1):
               f.write(f"{i}\n")
               f.write(f"{format_timestamp(start)} --> {format_timestamp(end)}\n")
               f.write(text + "\n\n")
   
   def split_sentence_with_time(start, end, text):
       """æŠŠä¸€å¥é‡Œå¤šä¸ªç»“æŸç¬¦æ‹†æˆå¤šå¥ï¼Œå¹¶æŒ‰å•è¯æ•°åˆ†é…æ—¶é—´"""
       parts = re.split(r"([.?!ã€‚ï¼Ÿï¼])", text)  # æŒ‰ç»“æŸç¬¦åˆ‡åˆ†
       chunks = []
       buffer = ""
       for p in parts:
           if not p.strip():
               continue
           buffer += p
           if p in SENT_END_CHARS:  # ç¢°åˆ°ç»“æŸç¬¦å°±è¾“å‡º
               chunks.append(buffer.strip())
               buffer = ""
       if buffer:  # å¦‚æžœæœ€åŽè¿˜æœ‰æ®‹ä½™ï¼ˆæ²¡æœ‰ç»“æŸç¬¦çš„ï¼‰
           chunks.append(buffer.strip())
   
       # æ—¶é—´åˆ†é…
       total_duration = end - start
       total_words = sum(len(c.split()) for c in chunks) or 1
       avg_word_time = total_duration / total_words
   
       result = []
       cur_start = start
       for c in chunks:
           word_count = len(c.split()) or 1
           cur_end = cur_start + word_count * avg_word_time
           result.append((cur_start, cur_end, c))
           cur_start = cur_end
       return result
   
   def merge_sentences(entries):
       merged = []
       cache = []
       for start, end, text in entries:
           cache.append((start, end, text))
           if text and text[-1] in SENT_END_CHARS:
               new_start = cache[0][0]
               new_end = cache[-1][1]
               new_text = " ".join([t for _, _, t in cache])
               merged.extend(split_sentence_with_time(new_start, new_end, new_text))
               cache = []
       if cache:
           new_start = cache[0][0]
           new_end = cache[-1][1]
           new_text = " ".join([t for _, _, t in cache])
           merged.append((new_start, new_end, new_text))
       return merged
   
   def process_file(file_path: str):
       if not file_path.lower().endswith(".srt"):
           return
       try:
           entries = read_srt(file_path)
           merged_entries = merge_sentences(entries)
           dir_name = os.path.dirname(file_path)
           base, ext = os.path.splitext(os.path.basename(file_path))
           output_path = os.path.join(dir_name, f"{base}-Merge{ext}")
           write_srt(merged_entries, output_path)
           print(f"âœ… å¤„ç†å®Œæˆ: {output_path}")
       except Exception as e:
           print(f"âŒ å¤„ç†å¤±è´¥ {file_path}: {e}")
   
   def process_path(path: str):
       if os.path.isfile(path):
           process_file(path)
       elif os.path.isdir(path):
           for root, _, files in os.walk(path):
               for name in files:
                   process_file(os.path.join(root, name))
       else:
           print(f"âš ï¸ è¾“å…¥è·¯å¾„æ— æ•ˆ: {path}")
   
   if __name__ == "__main__":
       # ðŸ‘‰ ä¿®æ”¹è¿™é‡Œçš„è·¯å¾„ï¼Œå¯ä»¥æ˜¯æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹
       input_path = "/Users/jiangsai/Downloads/1"
       process_path(input_path)
   
   ```

2. è‹±æ–‡è¯­éŸ³è½¬srtï¼Œä¸­æ–‡è¯­éŸ³è½¬txtï¼Œä¸€å¥è¯ä¸ä¼šä¸­æ–­

   ```python
   import os
   import re
   import time
   from zhconv import convert
   from faster_whisper import WhisperModel
   
   # ===================== å·¥å…·å‡½æ•° =====================
   def format_timestamp(seconds: float) -> str:
       """æŠŠç§’æ•°è½¬æˆ SRT æ—¶é—´æˆ³æ ¼å¼"""
       h = int(seconds // 3600)
       m = int((seconds % 3600) // 60)
       s = int(seconds % 60)
       ms = int(round((seconds - int(seconds)) * 1000))
       return f"{h:02}:{m:02}:{s:02},{ms:03}"
   
   # ===================== Step1: è½¬å½• (è¾“å‡ºä¸´æ—¶å­—å¹•) =====================
   def transcribe_audio_file(model, input_path, temp_output_path, mode):
       """è½¬å½•å•ä¸ªæ–‡ä»¶ï¼Œç”Ÿæˆä¸´æ—¶ SRT æˆ– TXT"""
       start_time = time.time()
       language = "en" if mode == "en" else "zh"
   
       segments, info = model.transcribe(input_path, language=language)
   
       if mode == "en":
           with open(temp_output_path, "w", encoding="utf-8") as srt_file:
               for idx, seg in enumerate(segments, start=1):
                   start = float(seg.start)
                   end = float(seg.end)
                   text = (seg.text or "").strip()
                   srt_file.write(f"{idx}\n")
                   srt_file.write(f"{format_timestamp(start)} --> {format_timestamp(end)}\n")
                   srt_file.write(f"{text}\n\n")
           print(f"è‹±æ–‡ä¸´æ—¶å­—å¹•å·²ç”Ÿæˆ: {temp_output_path}")
   
       elif mode == "zh":
           full_text = ""
           for seg in segments:
               full_text += (seg.text or "").strip() + "\n"
           simplified_text = convert(full_text, "zh-cn")
           with open(temp_output_path, "w", encoding="utf-8") as txt_file:
               txt_file.write(simplified_text)
           print(f"ä¸­æ–‡å­—å¹•å·²ç”Ÿæˆ: {temp_output_path}")
   
       elapsed_minutes = (time.time() - start_time) / 60
       rest_seconds = (int(elapsed_minutes // 10) + 1) * 60
       print(f"{input_path} è½¬å½•å®Œæˆï¼Œè€—æ—¶ {elapsed_minutes:.2f} åˆ†é’Ÿï¼Œä¼‘æ¯ {rest_seconds} ç§’ã€‚")
       time.sleep(rest_seconds)
   
   def transcribe_directory(model, folder_path, temp_dir, mode):
       """æ‰¹é‡è½¬å½•æ–‡ä»¶å¤¹"""
       os.makedirs(temp_dir, exist_ok=True)
       for root, dirs, files in os.walk(folder_path):
           dirs.sort()
           files.sort()
           for file in files:
               if file.endswith((".mp3", ".m4a", ".webm", ".mp4", ".mkv", ".avi", ".wav", ".flac")):
                   video_path = os.path.join(root, file)
                   temp_output_path = os.path.join(temp_dir, os.path.splitext(file)[0] + ".srt")
                   print(f"æ­£åœ¨è½¬å½•: {video_path}")
                   transcribe_audio_file(model, video_path, temp_output_path, mode)
   
   # ===================== Step2: åˆå¹¶å¥å­ =====================
   SENT_END_CHARS = set(".?!ã€‚ï¼Ÿï¼")
   
   def merge_srt_file(temp_path, final_path):
       """æŠŠä¸´æ—¶å­—å¹•åˆå¹¶æˆå®Œæ•´å¥å­"""
       with open(temp_path, "r", encoding="utf-8") as f:
           content = f.read().strip()
   
       # è§£æž SRT
       blocks = content.split("\n\n")
       entries = []
       for block in blocks:
           lines = block.strip().split("\n")
           if len(lines) >= 3:
               times = lines[1]
               text = " ".join(lines[2:]).strip()
               start, end = times.split(" --> ")
               entries.append((start, end, text))
   
       merged_entries = []
       buffer = []
       buffer_start = None
   
       for start, end, text in entries:
           if not buffer:  # æ–°ç¼“å­˜å¼€å§‹
               buffer_start = start
           buffer.append(text)
   
           if text and text[-1] in SENT_END_CHARS:
               merged_text = " ".join(buffer).strip()
               merged_entries.append((buffer_start, end, merged_text))
               buffer = []
               buffer_start = None
   
       if buffer:
           merged_entries.append((buffer_start, entries[-1][1], " ".join(buffer).strip()))
   
       with open(final_path, "w", encoding="utf-8") as f:
           for idx, (start, end, text) in enumerate(merged_entries, start=1):
               f.write(f"{idx}\n")
               f.write(f"{start} --> {end}\n")
               f.write(f"{text}\n\n")
   
       print(f"âœ… åˆå¹¶å®Œæˆ: {final_path}")
   
   def merge_directory(temp_dir, original_input):
       """æ‰¹é‡åˆå¹¶ temp_dir ä¸­çš„å­—å¹•ï¼Œè¾“å‡ºåˆ°åŽŸå§‹æ–‡ä»¶ç›®å½•"""
       for file in os.listdir(temp_dir):
           if file.endswith(".srt"):
               temp_path = os.path.join(temp_dir, file)
   
               # æ‰¾åˆ°åŽŸå§‹æ–‡ä»¶æ‰€åœ¨ç›®å½•
               base_name = os.path.splitext(file)[0]
               if os.path.isdir(original_input):  # æ‰¹é‡æ¨¡å¼
                   # éåŽ†åŽŸå§‹ç›®å½•ï¼Œæ‰¾åˆ°å¯¹åº”è§†é¢‘çš„ç›®å½•
                   for root, _, files in os.walk(original_input):
                       if any(f.startswith(base_name) for f in files):
                           final_path = os.path.join(root, base_name + ".srt")
                           break
               else:  # å•æ–‡ä»¶æ¨¡å¼
                   final_path = os.path.splitext(original_input)[0] + ".srt"
   
               merge_srt_file(temp_path, final_path)
   
   # ===================== ä¸»å…¥å£ =====================
   def cooking(input_path, whisper_model_name, mode):
       temp_dir = "temp_srt"
       model = WhisperModel(whisper_model_name, compute_type="int8")  # CPU æŽ¨è int8
   
       if os.path.isdir(input_path):
           transcribe_directory(model, input_path, temp_dir, mode)
       elif os.path.isfile(input_path):
           os.makedirs(temp_dir, exist_ok=True)
           temp_output_path = os.path.join(temp_dir, os.path.splitext(os.path.basename(input_path))[0] + ".srt")
           print(f"{input_path}ï¼Œæ­£åœ¨è½¬å½•...")
           transcribe_audio_file(model, input_path, temp_output_path, mode)
       else:
           print(f"âŒ æ— æ•ˆè·¯å¾„ï¼š{input_path}")
           return
   
       # ç¬¬äºŒæ­¥ï¼šåˆå¹¶å¥å­ï¼Œè¾“å‡ºåˆ°åŽŸå§‹ç›®å½•
       merge_directory(temp_dir, input_path)
   
   if __name__ == "__main__":
       input_path = "/Users/jiangsai/Downloads/å¹»å½±äº¤æ˜“2024/Module 7 - Entry Models/PTS-M7_2ã€Trading from Extreme or Decisional Levels.mp4"
       # æ¨¡åž‹å¯é€‰ "tiny", "base", "small", "medium", "large"
       whisper_model_name = "medium"     # è‹±æ–‡æŽ¨è "medium.en"ï¼Œä¸­è‹±æ··åˆ/ä¸­æ–‡ç”¨ "medium"
       mode = "en"  # "en" -> è‹±æ–‡SRT, "zh" -> ä¸­æ–‡TXT
       cooking(input_path, whisper_model_name, mode)
   
   ```

   ```python
   # æ–°æ¨¡åž‹
   # ç»å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œä½¿ç”¨ use_word_timestamps = Ture å¯ä»¥èŽ·å¾—æ›´å¥½çš„æ•ˆæžœ
   # ä½†ä¸ªåˆ«éŸ³é¢‘æ–‡ä»¶ï¼Œå¯èƒ½ä¼šæ–­å¥ä¼šæœ‰é—®é¢˜ï¼Œç”¨ use_word_timestamps = False é€æ®µè¾“å‡ºï¼Œæ‰‹åŠ¨ä¿®æ”¹å³å¯
   import os
   import time
   import re
   from zhconv import convert
   from faster_whisper import WhisperModel
   
   SENT_END_CHARS = set(".?!ã€‚ï¼Ÿï¼")
   ABBREVIATIONS = {
       "mr.", "mrs.", "dr.", "ms.", "prof.", "sr.", "jr.", "vs.", "etc.", "e.g.", "i.e.",
       "u.s.", "u.k.", "ph.d.", "a.m.", "p.m."
   }
   
   def format_timestamp(seconds):
       h = int(seconds // 3600)
       m = int((seconds % 3600) // 60)
       s = int(seconds % 60)
       ms = int(round((seconds - int(seconds)) * 1000))
       return f"{h:02}:{m:02}:{s:02},{ms:03}"
   
   def should_end_sentence(current_text):
       txt = current_text.strip()
       if not txt:
           return False
       last = txt[-1]
       if last not in SENT_END_CHARS:
           return False
       low = txt.lower()
       tail = low[-10:]
       for abbr in ABBREVIATIONS:
           if tail.endswith(abbr):
               return False
       return True
   
   def flush_sentence(entries, cur_words, cur_start, last_word_end):
       if not cur_words:
           return
       text = " ".join(cur_words).strip()
       text = re.sub(r"\s+([,.;:!?])", r"\1", text)  # åŽ»æŽ‰æ ‡ç‚¹å‰å¤šä½™ç©ºæ ¼
       entries.append((cur_start, last_word_end, text))
   
   def transcribe_audio_file(model, input_path, output_path, mode, gap_break_ms=1200, use_word_timestamps=True):
       start_time = time.time()
       language = "en" if mode == "en" else "zh"
   
       if use_word_timestamps:
           # æŒ‰å•è¯æ—¶é—´æˆ³æ–­å¥
           segments, info = model.transcribe(
               input_path,
               language=language,
               word_timestamps=True,
               vad_filter=True,
               vad_parameters={"min_silence_duration_ms": 300}
           )
       else:
           # åŽŸç‰ˆï¼šåªç”¨æ®µè½æ—¶é—´æˆ³
           segments, info = model.transcribe(
               input_path,
               language=language
           )
   
       if mode == "en":
           srt_path = output_path.replace(".txt", ".srt")
   
           if use_word_timestamps:
               # ===== æ–°é€»è¾‘ï¼šæŒ‰å®Œæ•´å¥å­åˆå¹¶ =====
               entries = []
               cur_words = []
               cur_start = None
               last_word_end = None
   
               for seg in segments:
                   if not seg.words:  # æ— å•è¯æ—¶é—´æˆ³ï¼ˆå¯èƒ½æ˜¯é™éŸ³æ®µï¼‰
                       if seg.text.strip():
                           if cur_start is None:
                               cur_start = float(seg.start)
                           last_word_end = float(seg.end)
                           cur_words.append(seg.text.strip())
                           if should_end_sentence(seg.text):
                               flush_sentence(entries, cur_words, cur_start, last_word_end)
                               cur_words, cur_start = [], None
                       continue
   
                   for w in seg.words:
                       w_text = (w.word or "").strip()
                       if not w_text:
                           continue
   
                       w_start = float(w.start)
                       w_end = float(w.end)
   
                       # é™éŸ³æ–­å¥
                       if cur_words and gap_break_ms and last_word_end is not None:
                           gap_ms = (w_start - last_word_end) * 1000.0
                           if gap_ms >= gap_break_ms:
                               flush_sentence(entries, cur_words, cur_start, last_word_end)
                               cur_words, cur_start = [], None
   
                       if cur_start is None:
                           cur_start = w_start
   
                       cur_words.append(w_text)
                       last_word_end = w_end
   
                       # æ ‡ç‚¹æ–­å¥
                       if should_end_sentence(" ".join(cur_words)):
                           flush_sentence(entries, cur_words, cur_start, last_word_end)
                           cur_words, cur_start = [], None
   
               flush_sentence(entries, cur_words, cur_start, last_word_end)
   
           else:
               # ===== æ—§é€»è¾‘ï¼šsegment å°±æ˜¯å­—å¹•è¡Œ =====
               entries = [
                   (float(seg.start), float(seg.end), seg.text.strip())
                   for seg in segments
               ]
   
           # å†™ SRT
           with open(srt_path, "w", encoding="utf-8") as srt_file:
               for idx, (start, end, text) in enumerate(entries, start=1):
                   srt_file.write(f"{idx}\n")
                   srt_file.write(f"{format_timestamp(start)} --> {format_timestamp(end)}\n")
                   srt_file.write(f"{text}\n\n")
   
           print(f"è‹±æ–‡å­—å¹•å·²ç”Ÿæˆ: {srt_path}")
   
       elif mode == "zh":
           full_text = ""
           for segment in segments:
               full_text += segment.text.strip() + "\n"
           simplified_text = convert(full_text, "zh-cn")
           with open(output_path, "w", encoding="utf-8") as txt_file:
               txt_file.write(simplified_text)
           print(f"ä¸­æ–‡å­—å¹•å·²ç”Ÿæˆ: {output_path}")
   
       elapsed_minutes = (time.time() - start_time) / 60
       rest_seconds = (int(elapsed_minutes // 10) + 1) * 60
       print(f"{input_path} è½¬å½•å®Œæˆï¼Œè€—æ—¶ {elapsed_minutes:.2f} åˆ†é’Ÿï¼Œä¼‘æ¯ {rest_seconds} ç§’ã€‚")
       time.sleep(rest_seconds)
   
   def transcribe_directory(model, folder_path, mode, use_word_timestamps):
       for root, dirs, files in os.walk(folder_path):
           dirs.sort()
           files.sort()
           for file in files:
               if file.endswith((".mp3", ".m4a", ".webm", ".mp4", ".mkv", ".avi", ".wav", ".flac")):
                   video_path = os.path.join(root, file)
                   output_path = os.path.splitext(video_path)[0] + ".txt"
                   print(f"æ­£åœ¨è½¬å½•: {video_path}")
                   transcribe_audio_file(model, video_path, output_path, mode, use_word_timestamps=use_word_timestamps)
   
   def cooking(input_path, whisper_model_name, mode, use_word_timestamps=True):
       model = WhisperModel(whisper_model_name, compute_type="int8")
   
       if os.path.isdir(input_path):
           transcribe_directory(model, input_path, mode, use_word_timestamps)
       elif os.path.isfile(input_path):
           output_path = os.path.splitext(input_path)[0] + ".txt"
           print(f"{input_path}ï¼Œæ­£åœ¨è½¬å½•...")
           transcribe_audio_file(model, input_path, output_path, mode, use_word_timestamps=use_word_timestamps)
       else:
           print(f"âŒ æ— æ•ˆè·¯å¾„ï¼š{input_path}")
   
   if __name__ == "__main__":
       input_path = '/Users/jiangsai/Downloads/å¹»å½±äº¤æ˜“2024/æœªå‘½åæ–‡ä»¶å¤¹/Module 3 - Market Structure/PTS-M3_5ã€Mapping Structure & Confirming Breaks of Structure.mp4'
       whisper_model_name = "medium"
       mode = "en"  # "en" -> è‹±æ–‡ SRT, "zh" -> ä¸­æ–‡ TXT
       use_word_timestamps = False  # True ç”¨æŒ‰å¥å­åˆå¹¶é€»è¾‘, False ç”¨åŽŸæ¥çš„é€æ®µè¾“å‡º
       cooking(input_path, whisper_model_name, mode, use_word_timestamps)
   ```

3. ï¼ˆæ–°æ¨¡åž‹-åºŸå¼ƒï¼‰è¯­éŸ³è½¬æ–‡å­—_æ¨¡åž‹whisper-ctranslate2

   > ```
   > pip install faster-whisper zhconv
   > // faster-whisper æ˜¯whisper-ctranslate2çš„Python å°è£…ç‰ˆ
   > // zhconv æ”¯æŒç®€ç¹ä½“è½¬æ¢
   > ```
   >
   > * æœ¬åœ°éŸ³è§†é¢‘è½¬æ–‡å­—
   >
   >   ```python
   >   import os
   >   import time
   >   from zhconv import convert
   >   from faster_whisper import WhisperModel
   >             
   >   # å¤„ç†å•ä¸ªéŸ³è§†é¢‘æ–‡ä»¶
   >   def transcribe_audio_file(model, input_path, output_path, language):
   >       start_time = time.time()  # å¼€å§‹è®¡æ—¶
   >             
   >       segments, info = model.transcribe(input_path, language=language)
   >       full_text = ""
   >       for segment in segments:
   >           full_text += segment.text + "\n"
   >             
   >       # zhconv è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡
   >       simplified_text = convert(full_text, "zh-cn")
   >             
   >       # ä¿å­˜åˆ°æ–‡ä»¶
   >       with open(output_path, "w") as f:
   >           f.write(simplified_text)
   >             
   >       end_time = time.time()
   >       elapsed_time = end_time - start_time
   >       elapsed_minutes = elapsed_time / 60
   >       rest_minutes = int(elapsed_minutes // 10) + 1
   >       rest_seconds = rest_minutes * 60
   >             
   >       print(f"{output_path} è½¬å½•å®Œæˆï¼Œè€—æ—¶ {elapsed_minutes:.2f} åˆ†é’Ÿï¼Œä¼‘æ¯ {rest_seconds} ç§’ï¼Œé¿å…CPUè¿‡çƒ­ã€‚")
   >       time.sleep(rest_seconds)
   >             
   >   # æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹
   >   def transcribe_directory(model, folder_path, language):
   >       for root, dirs, files in os.walk(folder_path):
   >           for file in files:
   >               if file.endswith((".mp3", ".m4a", ".webm", ".mp4", ".mkv", ".avi")):
   >                   video_path = os.path.join(root, file)
   >                   output_path = os.path.splitext(video_path)[0] + ".txt"
   >                   print(f"æ­£åœ¨è½¬å½•: {video_path}")
   >                   transcribe_audio_file(model, video_path, output_path, language)
   >             
   >   # å…¥å£å‡½æ•°
   >   def cooking(input_path, whisper_model_name):
   >       # "float16"ï¼ˆGPUï¼‰ï¼Œ"int8"ï¼ˆCPUï¼‰ï¼Œ"auto"ï¼ˆè‡ªåŠ¨é€‰ç”¨ GPU æˆ– CPUï¼‰
   >       model = WhisperModel(whisper_model_name, compute_type="int8")
   >             
   >       if os.path.isdir(input_path):
   >           transcribe_directory(model, input_path, language="zh")
   >       elif os.path.isfile(input_path):
   >           output_path = os.path.splitext(input_path)[0] + ".txt"
   >           print(f"{input_path}ï¼Œæ­£åœ¨è½¬å½•....")
   >           transcribe_audio_file(model, input_path, output_path, language="zh")
   >       else:
   >           print(f"æä¾›çš„è·¯å¾„æ— æ•ˆï¼š{input_path}")
   >             
   >   if __name__ == "__main__":
   >       input_path = '/Users/jiangsai/Downloads/mavnt011.mp3'
   >       whisper_model_name = "base"  # å¯ç”¨: "tiny", "base", "small", "medium", "large-v3"
   >       cooking(input_path, whisper_model_name)
   >   ```

4. ï¼ˆåºŸå¼ƒ-åŽŸç‰ˆçš„é€Ÿåº¦æ…¢è¿˜å èµ„æºï¼‰OpenAIè¯­éŸ³è½¬æ–‡å­—_æ¨¡åž‹Whisper

   > [æ•™ç¨‹](https://github.com/openai/whisper)
   >
   > ```bash
   > pip3 install -U openai-whisper
   > // ä¼šè‡ªåŠ¨ä¸‹è½½mediumæ¨¡åž‹åˆ° ~/.cache/whisper
   > cd /Users/jiangsai/Downloads
   > whisper audio.mp3 --model medium  //ä¼šé»˜è®¤ç”Ÿæˆjsonã€srtã€txtç­‰ç­‰æ–‡ä»¶
   > ```
   >
   > * æœ¬åœ°è§†é¢‘/éŸ³é¢‘è½¬æ–‡å­—
   >
   >   ```python
   >   import os
   >   import time
   >   import whisper
   >   from zhconv import convert
   >   
   >   # å¤„ç†å•ä¸ªéŸ³è§†é¢‘
   >   def transcribe_audio_file(model, input_path, output_path, language):
   >       start_time = time.time()  # å¼€å§‹è®¡æ—¶
   >   
   >       # ä½¿ç”¨Whisperæ¨¡åž‹è¿›è¡Œè¯­éŸ³è½¬æ–‡å­—
   >       result = model.transcribe(input_path, language=language)
   >       # å°†è½¬æ¢åŽçš„æ–‡å­—ä»Žç¹ä½“ä¸­æ–‡è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡
   >       simplified_text = convert(result["text"], "zh-cn")
   >       # å°†è½¬æ¢åŽçš„æ–‡å­—ä¿å­˜åˆ°æ–‡æœ¬æ–‡ä»¶ä¸­
   >       with open(output_path, "w") as f:
   >           f.write(simplified_text)
   >   
   >       end_time = time.time()  # ç»“æŸè®¡æ—¶
   >       elapsed_time = end_time - start_time  # èŠ±è´¹ç§’æ•°
   >       elapsed_minutes = elapsed_time / 60  # èŠ±è´¹åˆ†é’Ÿæ•°
   >   
   >       # è®¡ç®—ä¼‘æ¯æ—¶é—´ï¼šæ¯10åˆ†é’Ÿå¯¹åº”ä¼‘æ¯60ç§’
   >       rest_minutes = int(elapsed_minutes // 10) + 1
   >       rest_seconds = rest_minutes * 60
   >   
   >       print(f"{output_path} è½¬å½•å®Œæˆï¼Œè€—æ—¶ {elapsed_minutes:.2f} åˆ†é’Ÿï¼Œä¼‘æ¯ {rest_seconds} ç§’ï¼Œé¿å…CPUè¿‡çƒ­ã€‚")
   >       time.sleep(rest_seconds)
   >   
   >   # å¤„ç†æ–‡ä»¶å¤¹å†…çš„æ‰€æœ‰éŸ³è§†é¢‘
   >   def transcribe_directory(model, input_folder, language):
   >       # èŽ·å–æŒ‡å®šæ–‡ä»¶å¤¹å†…çš„æ‰€æœ‰è§†é¢‘æ–‡ä»¶
   >       video_files = [
   >           f for f in os.listdir(input_folder) if f.endswith((".mp3", ".m4a", ".webm", ".mp4", ".mkv", ".avi"))
   >       ]
   >   
   >       # å¤„ç†æ¯ä¸ªéŸ³è§†é¢‘
   >       for video_file in video_files:
   >           video_path = os.path.join(input_folder, video_file)
   >           transcription_path = os.path.join(input_folder, os.path.splitext(video_file)[0] + ".txt")
   >           print(f"{video_file}ï¼Œæ­£åœ¨è½¬å½•....")
   >           transcribe_audio_file(model, video_path, transcription_path, language)
   >   
   >   def cooking(input_path, whisper_model):
   >       model = whisper.load_model(whisper_model)
   >       if os.path.isdir(input_path):
   >           transcribe_directory(model, input_path, language="zh")
   >       elif os.path.isfile(input_path):
   >           output_path = os.path.splitext(input_path)[0] + ".txt"
   >           print(f"{input_path}ï¼Œæ­£åœ¨è½¬å½•....")
   >           transcribe_audio_file(model, input_path, output_path, language="zh")
   >       else:
   >           print(f"æä¾›çš„è·¯å¾„æ— æ•ˆï¼š{input_path}")
   >   
   >   if __name__ == "__main__":
   >       # è¦å¤„ç†çš„ç›®å½•æˆ–æ–‡ä»¶
   >       input_path = '/Users/jiangsai/Desktop/éƒ­ç£Šç¼ è®º'
   >       # åŠ è½½Whisperæ¨¡åž‹ "tiny", "base", "small", "medium", "large", "turbo"
   >       whisper_model = "turbo"
   >       cooking(input_path, whisper_model)
   >   ```
   >
   > * æœ¬åœ°è§†é¢‘åŠ å­—å¹•
   >
   >   ```python
   >   # å®‰è£… ffmpeg å’Œ translate-shellï¼šbrew install ffmpeg translate-shellï¼ˆè®¾ç½®å…¨å±€ä»£ç†ï¼Œåšå®¢æœâ€œä»£ç†â€œï¼‰
   >   # å®‰è£… openai-whisperï¼špip install openai-whisper
   >   import os
   >   import time
   >   import whisper
   >   import subprocess
   >                 
   >   # ä½¿ç”¨ translate-shell å°†è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡
   >   def translate_with_google(text):
   >       if not text.strip():
   >           return ""
   >       try:
   >           result = subprocess.run(
   >               ['trans', '-brief', ':zh', text],
   >               stdout=subprocess.PIPE,
   >               stderr=subprocess.DEVNULL,
   >               timeout=10,
   >               text=True
   >           )
   >           return result.stdout.strip()
   >       except Exception as e:
   >           print(f"[ç¿»è¯‘å¤±è´¥] {text} â†’ {e}")
   >           return "[ç¿»è¯‘å¤±è´¥]"
   >                 
   >   # å°†ç§’æ•°è½¬æ¢ä¸º SRT æ ¼å¼çš„æ—¶é—´æˆ³ï¼ˆå¦‚ 00:01:15,300ï¼‰
   >   def format_timestamp(seconds):
   >       h = int(seconds // 3600)
   >       m = int((seconds % 3600) // 60)
   >       s = int(seconds % 60)
   >       ms = int((seconds - int(seconds)) * 1000)
   >       return f"{h:02}:{m:02}:{s:02},{ms:03}"
   >                 
   >   # å¤„ç†å•ä¸ªéŸ³è§†é¢‘æ–‡ä»¶ï¼šè½¬å½• + ç”Ÿæˆ .srt åŒè¯­å­—å¹•
   >   def transcribe_audio_file(model, input_path, output_path, language):
   >       start_time = time.time()
   >                 
   >       # ä½¿ç”¨ Whisper è½¬å½•éŸ³é¢‘
   >       result = model.transcribe(input_path, language=language)
   >                 
   >       srt_path = output_path.replace(".txt", ".srt")
   >                 
   >       with open(srt_path, "w", encoding="utf-8") as f:
   >           for idx, segment in enumerate(result["segments"], start=1):
   >               eng = segment["text"].strip()
   >               zh = translate_with_google(eng)
   >               start = format_timestamp(segment["start"])
   >               end = format_timestamp(segment["end"])
   >                 
   >               f.write(f"{idx}\n")
   >               f.write(f"{start} --> {end}\n")
   >               f.write(f"{eng}\n")
   >               f.write(f"{zh}\n\n")
   >                 
   >               time.sleep(0.5)  # æŽ§åˆ¶ç¿»è¯‘é€ŸçŽ‡ï¼Œé¿å…é£ŽæŽ§
   >                 
   >       elapsed_minutes = (time.time() - start_time) / 60
   >       rest_seconds = (int(elapsed_minutes // 10) + 1) * 60
   >                 
   >       print(f"{srt_path} åŒè¯­å­—å¹•ç”Ÿæˆå®Œæ¯•ï¼Œç”¨æ—¶ {elapsed_minutes:.2f} åˆ†é’Ÿï¼Œä¼‘æ¯ {rest_seconds} ç§’é˜²æ­¢è¿‡çƒ­ã€‚")
   >       time.sleep(rest_seconds)
   >                 
   >   # æ‰¹é‡å¤„ç†ç›®å½•ä¸‹æ‰€æœ‰éŸ³è§†é¢‘æ–‡ä»¶
   >   def transcribe_directory(model, input_folder, language):
   >       # ç­›é€‰æ”¯æŒçš„è§†é¢‘éŸ³é¢‘æ–‡ä»¶æ ¼å¼
   >       video_files = [
   >           f for f in os.listdir(input_folder)
   >           if f.endswith((".mp3", ".m4a", ".webm", ".mp4", ".mkv", ".avi"))
   >       ]
   >                 
   >       for video_file in video_files:
   >           video_path = os.path.join(input_folder, video_file)
   >           txt_path = os.path.join(input_folder, os.path.splitext(video_file)[0] + ".txt")  # ç”¨äºŽç”Ÿæˆ srt æ–‡ä»¶å
   >           print(f"{video_file}ï¼Œå¼€å§‹ç”ŸæˆåŒè¯­å­—å¹•...")
   >           transcribe_audio_file(model, video_path, txt_path, language)
   >                 
   >   # ä¸»æŽ§åˆ¶å‡½æ•°ï¼šåˆ¤æ–­è·¯å¾„ç±»åž‹å¹¶è°ƒç”¨å¯¹åº”å¤„ç†é€»è¾‘
   >   def cooking(input_path, whisper_model):
   >       model = whisper.load_model(whisper_model)
   >                 
   >       if os.path.isdir(input_path):
   >           transcribe_directory(model, input_path, language="en")
   >       elif os.path.isfile(input_path):
   >           output_path = os.path.splitext(input_path)[0] + ".txt"
   >           print(f"{input_path}ï¼Œå¼€å§‹ç”ŸæˆåŒè¯­å­—å¹•...")
   >           transcribe_audio_file(model, input_path, output_path, language="en")
   >       else:
   >           print(f"âŒ æ— æ•ˆè·¯å¾„ï¼š{input_path}")
   >                 
   >   if __name__ == "__main__":
   >       # è¾“å…¥è·¯å¾„ï¼šå¯ä»¥æ˜¯å•ä¸ªè§†é¢‘ï¼Œä¹Ÿå¯ä»¥æ˜¯æ–‡ä»¶å¤¹
   >       input_path = '/Users/jiangsai/Downloads/TTT/1 - Introduction to the Course and to Trading.mp4'
   >       # Whisper æ¨¡åž‹ï¼šå»ºè®®ç”¨ base æˆ– smallï¼Œ"turbo" æ˜¯éžæ³•æ¨¡åž‹å
   >       whisper_model = "base"
   >       cooking(input_path, whisper_model)
   >                 
   >   ```
   >
   >   * åœ¨çº¿è§†é¢‘è½¬æ–‡å­—
   >
   >   ```python
   >    python
   >     import subprocess  # å¯¼å…¥subprocessæ¨¡å—ï¼Œç”¨äºŽæ‰§è¡Œç³»ç»Ÿå‘½ä»¤
   >     import whisper  # å¯¼å…¥whisperæ¨¡å—ï¼Œç”¨äºŽè¯­éŸ³è½¬æ–‡å­—
   >             
   >     # å®šä¹‰YouTubeè§†é¢‘çš„URL
   >       youtube_url = "https://www.youtube.com/watch?v=qZ3T5hunOuQ"
   >     # å®šä¹‰è¾“å‡ºçš„éŸ³é¢‘æ–‡ä»¶å
   >     output_audio = "audio.m4a"
   >             
   >     # ä½¿ç”¨yt-dlpä¸‹è½½éŸ³é¢‘å¹¶æå–ä¸ºm4aæ ¼å¼ï¼Œè®¾ç½®ä¸ºä½Žç­‰å“è´¨
   >       # -f bestaudio: é€‰æ‹©æœ€ä½³éŸ³é¢‘è´¨é‡
   >     # --extract-audio: åªæå–éŸ³é¢‘
   >     # --audio-format m4a: è½¬æ¢éŸ³é¢‘ä¸ºm4aæ ¼å¼
   >     # --audio-quality 2: è®¾ç½®éŸ³é¢‘è´¨é‡ä¸ºä½Žç­‰ï¼Œ0æœ€ä½Žï¼Œ9æœ€é«˜
   >     # -o output_audio: æŒ‡å®šè¾“å‡ºæ–‡ä»¶åä¸º output_audio
   >     subprocess.run(["yt-dlp", "-f", "bestaudio", "--extract-audio", "--audio-format", "m4a", "--audio-quality", "2", "-o", output_audio, youtube_url])
   >               
   >     # åŠ è½½Whisperæ¨¡åž‹
   >     # "base" æ˜¯æ¨¡åž‹çš„å¤§å°ï¼Œå¯ä»¥æ ¹æ®éœ€è¦é€‰æ‹© "tiny", "base", "small", "medium", "large"
   >     model = whisper.load_model("base")
   >               
   >     # ä½¿ç”¨Whisperæ¨¡åž‹è¯»å–éŸ³é¢‘æ–‡ä»¶å¹¶è¿›è¡Œè¯­éŸ³è½¬æ–‡å­—
   >     result = model.transcribe(output_audio)
   >               
   >     # æ‰“å°è½¬æ¢åŽçš„æ–‡å­—
   >     print(result["text"])
   >               
   >     # å°†è½¬æ¢åŽçš„æ–‡å­—ä¿å­˜åˆ°æ–‡æœ¬æ–‡ä»¶ä¸­
   >     # with open("transcription.txt", "w") as f:
   >     #     f.write(result["text"])
   > ```

5. å¾®è½¯æ–‡å­—è½¬è¯­éŸ³åº“

   > [æ•™ç¨‹](https://github.com/rany2/edge-tts)
   >
   > ```bash
   > //æ›´æ–°pip
   > pip install --upgrade pip
   > //å®‰è£…ä¾èµ–åº“
   > pip install cchardet
   > //å®‰è£…edge-tts
   > pip3 install edge-tts
   > ```
   >
   > * å®‰è£…åŽæµ‹è¯•
   >
   >   ```bash
   >   edge-tts --text "æ‰‹æœºå¾®ä¿¡æ‰«ç ç™»å½•ï¼ŒæˆåŠŸåŽæŒ‰å›žè½¦ç»§ç»­" --write-media 'test.mp3'
   >   ```
   >
   > * è½¬æ¢æŒ‡å®šæ–‡ä»¶
   >
   >   ```bash
   >   cd /Users/jiangsai/Desktop
   >   edge-tts -f "demo.txt" --write-media "demo.mp3"
   >   ```
   >
   > * è½¬æ¢æŒ‡å®šæ–‡ä»¶ - ä½¿ç”¨æŒ‡å®šè¯­éŸ³
   >
   >   ```bash
   >   edge-tts --voice zh-CN-YunxiNeural -f "demo.txt" --write-media "demo.mp3"
   >   ```
   >
   > * è°ƒæ•´è¯­é€Ÿ
   >
   >   ```bash
   >   //è¯­é€Ÿé™ä½Ž50%
   >   edge-tts --voice zh-CN-YunxiNeural --rate=-50% -f "demo.txt" --write-media "demo.mp3"
   >   //è¯­é€Ÿå¢žåŠ 50%
   >   edge-tts --voice zh-CN-YunxiNeural --rate=+50% -f "demo.txt" --write-media "demo.mp3"
   >   ```
   >
   > * è°ƒæ•´éŸ³é‡
   >
   >   ```bash
   >   //éŸ³é‡é™ä½Ž30%
   >   edge-tts --voice zh-CN-YunxiNeural --rate=-50% --volume=-30% -f "demo.txt" --write-media "demo.mp3"
   >   //éŸ³é‡å¢žåŠ 30%
   >   edge-tts --voice zh-CN-YunxiNeural --rate=+50% --volume=+30% -f "demo.txt" --write-media "demo.mp3"
   >   ```
   >
   > * æŸ¥çœ‹æ›´å¤šå‘éŸ³
   >
   >   ```bash
   >   (py3)  Sai  ~/Desktop ï¼šedge-tts --list-voices
   >   Name: af-ZA-AdriNeural
   >   Gender: Female
   >   
   >   Name: af-ZA-WillemNeural
   >   Gender: Male
   >   ```
   >
   >   ```python
   >   import os
   >   
   >   Voice_List = [
   >       "en-AU-NatashaNeural",
   >       "en-AU-WilliamNeural",
   >       "en-IN-NeerjaExpressiveNeural",
   >       "en-IN-PrabhatNeural",
   >       "en-US-AnaNeural",
   >       "en-US-JennyNeural",
   >       "en-US-RogerNeural",
   >       "en-US-SteffanNeural",
   >       "zh-CN-XiaoxiaoNeural",
   >       "zh-CN-XiaoyiNeural",
   >       "zh-CN-YunjianNeural",
   >       "zh-CN-YunxiaNeural",
   >       "zh-CN-YunxiNeural",
   >       "zh-CN-YunyangNeural",
   >       "zh-HK-HiuGaaiNeural",
   >       "zh-HK-WanLungNeural",
   >       "zh-TW-HsiaoChenNeural",
   >       "zh-TW-YunJheNeural",
   >   ]
   >   
   >   folderPath = "/Users/jiangsai/Desktop/1"
   >   
   >   for Voice in Voice_List:
   >       Voice_Path = f"{folderPath}/{Voice}.mp3"
   >       cmd = f'edge-tts --text "æ‰‹æœºå¾®ä¿¡æ‰«ç ç™»å½•ï¼ŒæˆåŠŸåŽæŒ‰å›žè½¦ç»§ç»­ï¼ŒOur companies have a track record of becoming billion dollar companies." --voice {Voice} --write-media "{Voice_Path}"'
   >       print(cmd)
   >       os.system(cmd)
   >   ```
   >
   > * Python æ–‡å­—è½¬æœ¬åœ°è¯­éŸ³è„šæœ¬
   >
   >   ```python
   >   import os
   >                                         
   >   Voice = "zh-CN-YunjianNeural"
   >   Rate = "+0%"
   >   Volume = "+0%"
   >                                         
   >   Handle_Folder = "/Users/jiangsai/Desktop/1"
   >                                         
   >   # è½¬æ¢ç›®å½•å†…æ‰€æœ‰å•ä¸ªtxtæ–‡ä»¶ä¸ºå•ä¸ªmp3éŸ³é¢‘
   >   for Folder_Path, SonFolders, FileNames in os.walk(Handle_Folder):
   >       for FileName in FileNames:
   >           if FileName.endswith(".txt"):
   >               # æŠŠ dirpath å’Œ æ¯ä¸ªæ–‡ä»¶åæ‹¼æŽ¥èµ·æ¥ å°±æ˜¯å…¨è·¯å¾„
   >               FilePath = f"{Folder_Path}/{FileName}"
   >               mp3Name = FileName.replace(".txt", ".mp3")
   >               mp3Path = f"{Folder_Path}/{mp3Name}"
   >               cmd = f'edge-tts --voice {Voice} --rate={Rate} --volume={Volume} -f {FilePath} --write-media "{mp3Path}"'
   >               os.system(cmd)
   >   ```

6. åˆ†å‰²ä¸­è‹±å­—å¹•è„šæœ¬

   ```python
   import re
   
   text = """Excuse me. My name is Richard Stewart. å¯¹ä¸èµ·ï¼Œæˆ‘å«Richard Stewartã€‚
   I'm a photographer. æˆ‘æ˜¯ä¸€ä½æ‘„å½±å¸ˆã€‚"""
   
   # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åœ¨æ¯æ®µä¸­æ–‡çš„ç¬¬ä¸€ä¸ªæ±‰å­—å‰é¢å¢žåŠ æ•°å­—112
   result = re.sub(r"(^|[^\u4e00-\u9fff])([\u4e00-\u9fff])", r"\1 åˆ†å‰²è¯ \2", text, count=1)
   result = re.sub(r"([ã€‚ï¼ï¼Ÿ\n])([^\u4e00-\u9fff]*)([\u4e00-\u9fff])", r"\1\2 åˆ†å‰²è¯ \3", result)
   
   print(result)
   ```

7. èŽ·å–ç›®å½•ä¸‹æ‰€æœ‰è§†é¢‘çš„æ—¶é•¿

   ```python
   import os
   import subprocess
   import csv
   
   
   def get_video_duration(file_path):
       """
       èŽ·å–è§†é¢‘æ–‡ä»¶çš„æ—¶é•¿ï¼ˆæ ¼å¼ï¼šç§’ï¼‰
       """
       try:
           result = subprocess.run(
               ["ffprobe", "-v", "error", "-show_entries", "format=duration", "-of", "default=noprint_wrappers=1:nokey=1", file_path],
               stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
           )
           duration = float(result.stdout.strip())
           return duration
       except Exception:
           return 0  # å¦‚æžœå‡ºé”™ï¼Œè¿”å›ž0ç§’
   
   
   def format_duration(seconds):
       """
       å°†ç§’è½¬æ¢ä¸º hh:mm:ss æ ¼å¼
       """
       hours = int(seconds // 3600)
       minutes = int((seconds % 3600) // 60)
       secs = int(seconds % 60)
       return f"{hours:02}:{minutes:02}:{secs:02}"
   
   
   def generate_markdown_table(directory):
       """
       éåŽ†ç›®å½•ï¼Œç”Ÿæˆåˆ†ç»„ Markdown æ ¼å¼çš„è¡¨æ ¼
       """
       markdown_lines = ["| Video Name | Duration |", "|------------|----------|"]
       previous_dir = None
       directory_total_duration = 0  # å½“å‰ç›®å½•æ€»æ—¶é•¿
       temp_video_lines = []  # ä¸´æ—¶å­˜å‚¨å½“å‰ç›®å½•çš„è§†é¢‘è¡Œ
   
       for root, _, files in sorted(os.walk(directory)):
           # ç­›é€‰å‡ºè§†é¢‘æ–‡ä»¶
           video_files = [file for file in files if file.lower().endswith(('.mp4', '.mkv', '.avi', '.mov'))]
           if not video_files:
               continue
   
           # å½“å‰ç›®å½•çš„åç§°
           current_dir = os.path.basename(root) or "."
   
           # å¦‚æžœåˆ‡æ¢åˆ°æ–°çš„ç›®å½•ï¼Œè¾“å‡ºä¸Šä¸€ä¸ªç›®å½•çš„æ€»æ—¶é•¿å’Œè§†é¢‘è¡Œ
           if previous_dir is not None and previous_dir != current_dir:
               markdown_lines.append(f"| **{previous_dir} (Total)** | **{format_duration(directory_total_duration)}** |")
               markdown_lines.extend(temp_video_lines)
               temp_video_lines = []  # æ¸…ç©ºä¸´æ—¶è¡Œ
               directory_total_duration = 0  # é‡ç½®æ€»æ—¶é•¿
   
           previous_dir = current_dir
   
           # æ·»åŠ å½“å‰ç›®å½•çš„è§†é¢‘ä¿¡æ¯
           for file in sorted(video_files):
               file_path = os.path.join(root, file)
               duration = get_video_duration(file_path)
               directory_total_duration += duration
               temp_video_lines.append(f"| {file} | {format_duration(duration)} |")
   
       # è¾“å‡ºæœ€åŽä¸€ä¸ªç›®å½•çš„æ€»æ—¶é•¿å’Œè§†é¢‘è¡Œ
       if previous_dir is not None:
           markdown_lines.append(f"| **{previous_dir} (Total)** | **{format_duration(directory_total_duration)}** |")
           markdown_lines.extend(temp_video_lines)
   
       return "\n".join(markdown_lines)
   
   
   def generate_csv_file(directory, output_csv_path):
       """
       éåŽ†ç›®å½•ï¼Œç”Ÿæˆ CSV æ–‡ä»¶
       """
       with open(output_csv_path, mode='w', newline='', encoding='utf-8-sig') as csv_file:
   
           csv_writer = csv.writer(csv_file)
           csv_writer.writerow(["Directory", "Video Name", "Duration (hh:mm:ss)", "Duration (seconds)"])
   
           previous_dir = None
           directory_total_duration = 0  # å½“å‰ç›®å½•æ€»æ—¶é•¿
   
           for root, _, files in sorted(os.walk(directory)):
               # ç­›é€‰å‡ºè§†é¢‘æ–‡ä»¶
               video_files = [file for file in files if file.lower().endswith(('.mp4', '.mkv', '.avi', '.mov'))]
               if not video_files:
                   continue
   
               # å½“å‰ç›®å½•çš„åç§°
               current_dir = os.path.basename(root) or "."
   
               # å¦‚æžœåˆ‡æ¢åˆ°æ–°çš„ç›®å½•ï¼Œè¾“å‡ºä¸Šä¸€ä¸ªç›®å½•çš„æ€»æ—¶é•¿
               if previous_dir is not None and previous_dir != current_dir:
                   csv_writer.writerow([f"{previous_dir} (Total)", "", format_duration(directory_total_duration), directory_total_duration])
                   directory_total_duration = 0  # é‡ç½®æ€»æ—¶é•¿
   
               previous_dir = current_dir
   
               # æ·»åŠ å½“å‰ç›®å½•çš„è§†é¢‘ä¿¡æ¯
               for file in sorted(video_files):
                   file_path = os.path.join(root, file)
                   duration = get_video_duration(file_path)
                   directory_total_duration += duration
                   csv_writer.writerow([current_dir, file, format_duration(duration), duration])
   
           # è¾“å‡ºæœ€åŽä¸€ä¸ªç›®å½•çš„æ€»æ—¶é•¿
           if previous_dir is not None:
               csv_writer.writerow([f"{previous_dir} (Total)", "", format_duration(directory_total_duration), directory_total_duration])
   
   
   if __name__ == "__main__":
       # æŒ‡å®šè¦æ‰«æçš„ç›®å½•
       directory_to_scan = "/Users/jiangsai/Downloads/ç²¾å“ç­ PremumClass001"
       
       # ç”Ÿæˆ Markdown è¡¨æ ¼
       markdown_table = generate_markdown_table(directory_to_scan)
       
       # è¾“å‡º Markdown è¡¨æ ¼åˆ°ç»ˆç«¯
       print(markdown_table)
       
       # ä¿å­˜ Markdown è¡¨æ ¼åˆ°æ–‡ä»¶
       markdown_output_path = os.path.join(directory_to_scan, "video_durations.md")
       with open(markdown_output_path, "w") as md_file:
           md_file.write(markdown_table)
       
       # ç”Ÿæˆ CSV æ–‡ä»¶
       csv_output_path = os.path.join(directory_to_scan, "video_durations.csv")
       generate_csv_file(directory_to_scan, csv_output_path)
   ```

8. æ‰¹é‡åˆ é™¤æ–‡ä»¶å¤¹å†…æ‰€æœ‰è§†é¢‘çš„å¼€å¤´ x ç§’ï¼Œç»“å°¾ y ç§’

   > ```python
   > import subprocess
   > import os
   > 
   > # è¦å¤„ç†çš„è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„
   > video_folder = "/Users/jiangsai/Desktop/tt"
   > 
   > # å¤„ç†åŽçš„è§†é¢‘ä¿å­˜çš„æ–‡ä»¶å¤¹
   > output_folder = "/Users/jiangsai/Desktop/ss"
   > if not os.path.exists(output_folder):
   >  os.makedirs(output_folder)
   > 
   > # è¦åˆ é™¤çš„å¼€å¤´æ—¶é•¿å’Œç»“å°¾æ—¶é•¿
   > start_duration = 24  # å¼€å¤´æ—¶é•¿
   > end_duration = 8  # ç»“å°¾æ—¶é•¿
   > 
   > # èŽ·å–æ–‡ä»¶å¤¹å†…æ‰€æœ‰çš„è§†é¢‘æ–‡ä»¶
   > videos = [f for f in os.listdir(video_folder) if f.endswith((".mp4", ".mkv", ".avi"))]
   > 
   > for video in videos:
   >  input_path = os.path.join(video_folder, video)
   >  output_path = os.path.join(output_folder, f"trimmed_{video}")
   > 
   >  # èŽ·å–è§†é¢‘æ€»æ—¶é•¿
   >  cmd = f'ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "{input_path}"'
   >  total_duration = float(subprocess.check_output(cmd, shell=True).decode("utf-8").strip())
   > 
   >  # è®¡ç®—è£å‰ªåŽçš„è§†é¢‘é•¿åº¦
   >  trimmed_duration = total_duration - start_duration - end_duration
   > 
   >  # ä½¿ç”¨ffmpegå‘½ä»¤è¡Œå·¥å…·æ¥è£å‰ªè§†é¢‘
   >  cmd = f'ffmpeg -y -i "{input_path}" -ss {start_duration} -t {trimmed_duration} -c copy "{output_path}"'
   >  subprocess.call(cmd, shell=True)
   > 
   > print("æ‰€æœ‰è§†é¢‘å¤„ç†å®Œæ¯•ã€‚")
   > ```

9. PDFè½¬txt

   ```python
   import fitz, re  # PyMuPDF
   
   
   # PDFè½¬txt
   def extract_and_clean_text(pdf_path):
       # Open the PDF file
       pdf_document = fitz.open(pdf_path)
       text = ""
       # Iterate through each page
       for page_num in range(len(pdf_document)):
           page = pdf_document.load_page(page_num)
           # Extract text from the page
           page_text = page.get_text("text")
           if "645 æ¥¼" in page_text:
               pass
           # å¤„ç†æ®µè½
           page_text = clean_text(page_text)
           # Clean text by removing extra whitespace and newlines
           text += page_text + "\n"
       return text.strip()
   
   
   # å¤„ç†å­—ç¬¦ä¸²ï¼šã€åˆ é™¤ç©ºè¡Œã€ã€åˆ é™¤ã€Œ---ã€
   def clean_text(text):
       # åˆ é™¤ ã€Œ@ç†Šç†Š chn 2016-03-25 16:05:01ã€è¿™ç§å­—ç¬¦
       text = re.sub(r"@\S.*?\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}", "", text)
       # åˆ é™¤ã€Œ@åˆ®è¥¿åŒ—é£Ž2017-08-19ã€
       text = re.sub(r"@\S+\d{4}-\d{2}-\d{2}", "", text)
       # åˆ é™¤ ã€Œä½œè€…:å†»äº‘è¿·é›¾ã€è¿™ç±»å­—ç¬¦
       text = re.sub(r"ä½œè€…:\S+", "", text)
       text = re.sub(r"æ¥¼ä¸»:\S+", "", text)
       # åˆ é™¤ ã€Œæ—¥æœŸ:2014-05-01ã€è¿™ç±»å­—ç¬¦
       text = re.sub(r"æ—¥æœŸ:\d{4}-\d{2}-\d{2}", "", text)
       # åˆ é™¤ ã€Œ[img]http://img3.xxx.cn/xxx.png[/img]ã€ã€Œhttp://news\.xxx\.com\.xxx.shtmlã€
       text = re.sub(r"\[img\]\S+\[/img\]", "", text)
       text = re.sub(r"http\S+", "", text)
       # åˆ é™¤å¤šä¸ªè¿žå­—ç¬¦"-"
       text = re.sub(r"-{2,}", "", text)
       # åˆ é™¤ç©ºæ ¼
       text = text.replace(" ", "")
       # åˆ é™¤ è‡ªæ¥ xxxæ¥¼
       text = re.sub(r"æ¥è‡ª\n\d+æ¥¼", "", text)
       # åˆ é™¤ \n
       text = text.replace("\n", "")
       # åˆ é™¤æ¯è¡Œå‰é¢çš„æ•°å­—
       # text = re.sub(r"^\d+", "", text, flags=re.MULTILINE)
       return text
   
   
   # å¾…å¤„ç†PDFæ–‡ä»¶è·¯å¾„
   pdf_path = "/Users/jiangsai/Downloads/å¤©æ¶¯å…¨é›†/208-è™šæ‹Ÿè´§å¸çš„ç§˜å¯†ï¼Œå…¼è°ˆæ¯”ç‰¹å¸çš„æœªæ¥å’Œå„å›½çš„æˆ˜ç•¥å¸ƒå±€.pdf"
   final_text = extract_and_clean_text(pdf_path)
   
   # ä¿å­˜åˆ°txtæ–‡ä»¶
   output_txt_path = "/Users/jiangsai/Desktop/1.txt"
   with open(output_txt_path, "w", encoding="utf-8") as txt_file:
       txt_file.write(final_text)
   
   ```

10. å®šæ—¶æé†’

   1. æ¯15åˆ†é’Ÿæé†’1æ¬¡

      > ```python
      > # æ—¶é—´ä¸º15çš„å€æ•°æ—¶é“ƒå£°æé†’ 1:15,1:30,1:45
      > import time
      > import os
      > 
      > def play_audio():
      >     # ä½¿ç”¨ afplay æ’­æ”¾éŸ³é¢‘
      >     os.system('afplay /Users/sai/Downloads/å†¥æƒ³-è¿åŠ¨/å®å’š.MP3') 
      > 
      > while True:
      >     current_time = time.localtime()
      >     minutes = current_time.tm_min
      > 
      >     if minutes % 15 == 0:
      >         print(f"å½“å‰æ—¶é—´: {time.strftime('%H:%M', current_time)} - æ’­æ”¾éŸ³é¢‘")
      >         play_audio()
      >         time.sleep(60)
      > 
      >     time.sleep(1)
      > ```
      >
      > * æ›´æ¢ç³»ç»ŸéŸ³æ•ˆ
      >
      >   > macOS å†…ç½®éŸ³æ•ˆè·¯å¾„æ˜¯ï¼š`/System/Library/Sounds/`
      >   >
      >   > å¯æ”¹æˆï¼š`afplay /System/Library/Sounds/Ping.aiff`
      >   >
      >   > æ”¹æˆä»»ä¸€éŸ³é¢‘ï¼š`subprocess.run(["afplay", " ~/Desktop/æç¤ºéŸ³.mp3"])`

   2. æ¯5åˆ†é’Ÿæé†’1æ¬¡ï¼Œå¹¶åšå‡ºæ¡Œé¢å›¾æ ‡

      > ```python
      > import time
      > import subprocess
      > from datetime import datetime
      > 
      > def send_notification(title, message):
      >  subprocess.run([
      >      "osascript", "-e",
      >      f'display notification "{message}" with title "{title}"'
      >  ])
      > def play_system_sound():
      >  # æ’­æ”¾ç³»ç»Ÿæç¤ºéŸ³ï¼ˆSosumiï¼‰
      >  subprocess.run([
      >      "afplay", "/System/Library/Sounds/Sosumi.aiff"
      >  ])
      > 
      > def next_5_minute():
      >  now = datetime.now()
      >  # è®¡ç®—å½“å‰æ—¶é—´åˆ°ä¸‹ä¸€ä¸ª5åˆ†é’Ÿå€æ•°çš„æ—¶é—´
      >  minutes_to_next_5 = 5 - now.minute % 5
      >  seconds_to_next_5 = minutes_to_next_5 * 60 - now.second
      >  return seconds_to_next_5
      > 
      > while True:
      >  # è®¡ç®—åˆ°ä¸‹ä¸€ä¸ª5åˆ†é’Ÿå€æ•°çš„æ—¶é—´
      >  wait_time = next_5_minute()
      >  time.sleep(wait_time)
      >  play_system_sound()
      >  send_notification("5åˆ†é’Ÿäº†", "çœ‹ä¸€çœ¼ç›˜é¢")
      >  # ç­‰å¾…åˆ°ä¸‹ä¸€ä¸ª5åˆ†é’Ÿå€æ•°
      >  time.sleep(30)
      > ```
      >
      > ![image-20250409161602383](https://raw.githubusercontent.com/jiangsai0502/PicBedRepo/master/image-20250409161602383.png)
      >
      > 1. æ‰“å¼€ **Automator** â†’ **æ–°å»ºæ–‡ç¨¿** â†’ é€‰æ‹© **åº”ç”¨ç¨‹åº** â†’ å·¦ä¾§æœç´¢æ¡†è¾“å…¥ `Shell`ï¼ŒåŒå‡»ã€Œè¿è¡Œ Shell è„šæœ¬ã€ â†’ æ›¿æ¢é»˜è®¤å†…å®¹ï¼š`python3 ~/Desktop/reminder.py` 
      >
      >    > å¦‚æžœæŠ¥é”™å¯ä»¥æŒ‡å®šPythonç‰ˆæœ¬
      >    >
      >    > ```bash
      >    > which python3
      >    > /opt/anaconda3/bin/python3
      >    > ```
      >    >
      >    > ã€Œ Shell è„šæœ¬ã€ æ›¿æ¢æˆ
      >    >
      >    > `/opt/anaconda3/bin/python3 ~/Desktop/reminder.py`
      >
      > 2. ç‚¹å‡»å·¦ä¸Šè§’ã€Œæ–‡ä»¶ã€â†’ã€Œå­˜å‚¨ã€ï¼Œä¿å­˜åˆ°æ¡Œé¢ï¼Œæ¯”å¦‚å« `5åˆ†é’Ÿæé†’.app`
      >
      > 3. åŒå‡»è¿™ä¸ª `.app`ï¼Œå®ƒå°±ä¼šå¯åŠ¨ä½ çš„æé†’ç¨‹åºäº†
      >
      > **æ€æŽ‰ç¨‹åº**
      >
      > * **æ´»åŠ¨ç›‘è§†å™¨**ï¼šæœç´¢æ¡†è¾“ï¼š`python`

   3. çœ‹ç›˜æé†’

      > ç”¨æ³•ï¼šç”¨`reminder.command`æŽ§åˆ¶`reminder.py`ï¼ŒåŒå‡»`.command` æ¥å¼€å…³ç¨‹åº
      >
      > 1. `reminder.py`
      >
      >    ```python
      >    # å‚æ•°1ï¼špython reminder.py 1 æ¯éš”åŠå°æ—¶è¯­éŸ³æŠ¥æ—¶ 
      >    # å‚æ•°2ï¼špython reminder.py 2 æ¯éš”5åˆ†é’Ÿé“ƒå£°æé†’ + æ¯éš”åŠå°æ—¶è¯­éŸ³æŠ¥æ—¶ 
      >    # å‚æ•°3ï¼špython reminder.py 3 æ¯éš”3åˆ†é’Ÿé“ƒå£°æé†’ + æ¯éš”15åˆ†é’Ÿè¯­éŸ³æŠ¥æ—¶
      >    import os
      >    import sys
      >    import subprocess
      >    import time
      >    from datetime import datetime
      >    import asyncio
      >                            
      >    # ä¸­æ–‡æ•°å­—æ˜ å°„
      >    chinese_nums = {
      >     0: 'é›¶', 1: 'ä¸€', 2: 'äºŒ', 3: 'ä¸‰', 4: 'å››',
      >     5: 'äº”', 6: 'å…­', 7: 'ä¸ƒ', 8: 'å…«', 9: 'ä¹', 10: 'å'
      >    }
      >                            
      >    def num_to_chinese(n):
      >     if n < 10:
      >         return chinese_nums[n]
      >     elif n == 10:
      >         return 'å'
      >     elif n < 20:
      >         return 'å' + chinese_nums[n % 10]
      >     else:
      >         return chinese_nums[n // 10] + 'å' + (chinese_nums[n % 10] if n % 10 != 0 else '')
      >                            
      >    def get_chinese_time():
      >     now = datetime.now()
      >     hour_ch = num_to_chinese(now.hour)
      >     minute_ch = num_to_chinese(now.minute) if now.minute != 0 else 'æ•´'
      >     return f"{hour_ch}ç‚¹{minute_ch}"
      >                            
      >    async def speak(text):
      >     from edge_tts import Communicate
      >     communicate = Communicate(text, voice="zh-CN-XiaoxiaoNeural")
      >     await communicate.save("output.mp3")
      >     os.system("afplay output.mp3")
      >                            
      >    def send_notification(title, message):
      >     subprocess.run([
      >         "osascript", "-e",
      >         f'display notification "{message}" with title "{title}"'
      >     ])
      >                            
      >    def play_system_sound():
      >     subprocess.run(["afplay", "/System/Library/Sounds/Sosumi.aiff"])
      >                            
      >    def main_loop(mode):
      >     already_triggered = None
      >     while True:
      >         now = datetime.now()
      >         key = f"{now.hour}:{now.minute}"
      >         if now.second == 0 and key != already_triggered:
      >             minute = now.minute
      >                            
      >             # æ¨¡å¼ 1ï¼šF30ï¼ˆæ•´ç‚¹å’ŒåŠç‚¹æ’­æŠ¥æ—¶é—´ï¼‰
      >             if mode == "1":
      >                 if minute in [0, 30]:
      >                     ch_time = get_chinese_time()
      >                     asyncio.run(speak(f"{ch_time}"))
      >                            
      >             # æ¨¡å¼ 2ï¼šF5ï¼ˆæ¯5åˆ†é’Ÿæç¤ºï¼Œæ•´ç‚¹å’ŒåŠç‚¹è¯­éŸ³ï¼‰
      >             elif mode == "2":
      >                 if minute in [0, 30]:
      >                     ch_time = get_chinese_time()
      >                     asyncio.run(speak(f"{ch_time}"))
      >                 elif minute % 5 == 0:
      >                     play_system_sound()
      >                     send_notification("5åˆ†é’Ÿäº†", "çœ‹ä¸€çœ¼ç›˜é¢")
      >                            
      >             # æ¨¡å¼ 3ï¼šF15+F3ï¼ˆ15/30/45/æ•´ç‚¹æ’­æŠ¥ï¼Œå…¶ä½™æ¯3åˆ†é’Ÿæé†’ï¼‰
      >             elif mode == "3":
      >                 if minute in [0, 15, 30, 45]:
      >                     ch_time = get_chinese_time()
      >                     asyncio.run(speak(f"{ch_time}"))
      >                 elif minute % 3 == 0 and minute not in [0, 15, 30, 45]:
      >                     play_system_sound()
      >                     send_notification("3åˆ†é’Ÿäº†", "ç›¯ä¸€ä¸‹ç›˜é¢")
      >                            
      >             already_triggered = key
      >         time.sleep(1)
      >    
      >    
      >    
      >    if __name__ == "__main__":
      >     if len(sys.argv) != 2 or sys.argv[1] not in ["1", "2", "3"]:
      >         send_notification("è¿è¡Œå‚æ•°é”™è¯¯", "ç”¨æ³•ï¼špython reminder.py 1 æˆ– 2 æˆ– 3")
      >         asyncio.run(speak("å‚æ•°é”™è¯¯ï¼Œå‚æ•°åªèƒ½æ˜¯ä¸€ã€äºŒæˆ–ä¸‰"))
      >         sys.exit(1)
      >    
      >     mode = sys.argv[1]
      >     main_loop(mode)
      >
      > 2. `reminder.command`
      >
      >    ```bash
      >    #!/bin/bash
      >                            
      >    LOCK_FILE="$HOME/.reminder.lock"
      >    SCRIPT_PATH="$HOME/Downloads/Pythonè„šæœ¬/reminder.py"
      >                            
      >    # å¦‚æžœé”æ–‡ä»¶å­˜åœ¨ï¼Œè¯»å–å…¶ä¸­çš„ PID
      >    if [ -f "$LOCK_FILE" ]; then
      >        OLD_PID=$(cat "$LOCK_FILE")
      >                            
      >        # æ£€æŸ¥è¯¥ PID æ˜¯å¦ä»åœ¨è¿è¡Œä¸”æ˜¯æˆ‘ä»¬è¿™ä¸ªè„šæœ¬
      >        if ps -p "$OLD_PID" > /dev/null && ps -p "$OLD_PID" -o args= | grep -q "$SCRIPT_PATH"; then
      >            # æ˜¯åœ¨è¿è¡Œä¸­ï¼Œå…³é—­å®ƒ
      >            kill "$OLD_PID"
      >            rm -f "$LOCK_FILE"
      >            osascript -e 'display notification "ç¨‹åºå·²å…³é—­" with title "æé†’åŠ©æ‰‹"'
      >            exit 0
      >        else
      >            # PID ä¸å­˜åœ¨æˆ–ä¸æ˜¯æˆ‘ä»¬çš„è„šæœ¬ï¼Œç§»é™¤é”æ–‡ä»¶
      >            rm -f "$LOCK_FILE"
      >        fi
      >    fi
      >                            
      >    # å¯åŠ¨è„šæœ¬ï¼ˆåŽå°ï¼‰ï¼Œä¿å­˜ PID
      >    /opt/anaconda3/bin/python3 "$SCRIPT_PATH" 2 &
      >    NEW_PID=$!
      >    echo "$NEW_PID" > "$LOCK_FILE"
      >    osascript -e 'display notification "ç¨‹åºå·²å¯åŠ¨" with title "æé†’åŠ©æ‰‹"'
      >                            
      >    exit 0
      >    ```

11. ç›‘æŽ§å¸å®‰çš„å¸ä»·ï¼Œè¾¾åˆ°æŸä¸ªä»·æ ¼åŒºåŸŸæ—¶ï¼Œé‚®ä»¶æé†’

   > ```python
   > import requests, time, smtplib, datetime
   > from email.mime.text import MIMEText
   > from email.mime.multipart import MIMEMultipart
   > 
   > # é‚®ä»¶å‘é€å‡½æ•°
   > def send_mail(subject, body, to_email):
   >     # é‚®ä»¶æœåŠ¡å™¨é…ç½®
   >     from_email = "jiangsai0502@gmail.com" # å‘ä»¶äººé‚®ç®±
   >     # 1. å¼€å¯ä¸¤æ­¥éªŒè¯
   >     # 2. åœ¨https://myaccount.google.com/u/6/apppasswords?gar=1ï¼Œåˆ›å»ºä¸€ä¸ªåº”ç”¨ç‰¹å®šå¯†ç 
   >     from_email_password = "ygms zuth hmyd rgsm"
   >     mail_server = "smtp.gmail.com"  # å‘ä»¶äººé‚®ç®±SMTPæœåŠ¡å™¨åœ°å€
   >     mail_port = 587  # SMTPç«¯å£
   >     
   >     # æž„é€ é‚®ä»¶å†…å®¹
   >     msg = MIMEMultipart()
   >     msg["From"] = from_email
   >     msg["To"] = to_email
   >     msg["Subject"] = subject
   >     msg.attach(MIMEText(body, "plain"))
   > 
   >     try:
   >         server = smtplib.SMTP(mail_server, mail_port)
   >         server.starttls()
   >         server.login(from_email, from_email_password)
   >         server.sendmail(from_email, to_email, msg.as_string())
   >         server.quit()
   >         print("âœ… é‚®ä»¶å·²å‘é€ï¼")
   >     except Exception as e:
   >         print(f"âŒ å‘é€é‚®ä»¶å‡ºé”™ï¼š{e}")
   > 
   > # èŽ·å–åŠ å¯†è´§å¸ä»·æ ¼
   > def get_crypto_price(symbol):
   >     url = "https://api.binance.com/api/v3/ticker/price"
   >     params = {"symbol": symbol}
   >     try:
   >         response = requests.get(url, params=params, timeout=5)
   >         if response.status_code == 200:
   >             data = response.json()
   >             return float(data["price"])
   >     except Exception as e:
   >         print(f"èŽ·å– {symbol} ä»·æ ¼å¤±è´¥ï¼š{e}")
   >     return None
   > 
   > # åˆ¤æ–­æ˜¯å¦æ˜¯æ•´ç‚¹æˆ–åŠç‚¹
   > def is_summary_time():
   >     now = datetime.datetime.now()
   >     # return now.minute in [0, 30] and now.second < 10  # å‰10ç§’å†…è§¦å‘
   >     return now.minute % 5 == 0 and now.second < 10  # æµ‹è¯•æ¯5åˆ†é’Ÿå‘ä¸€æ¬¡ï¼Œå‰10ç§’å†…è§¦å‘
   > 
   > # ä¸»å¾ªçŽ¯
   > def monitor_crypto():
   >     crypto_symbols = {
   >         "BTCUSDT": {"min_price": 25000, "max_price": 130000},
   >         "ETHUSDT": {"min_price": 1800, "max_price": 3000}
   >     }
   > 
   >     to_email = "jiangsai0502@outlook.com"
   > 
   >     # åˆå§‹åŒ–çŠ¶æ€ç¼“å­˜
   >     hit_count = {symbol: 0 for symbol in crypto_symbols}
   >     triggered = set()
   >     last_summary_minute = -1  # é¿å…ä¸€åˆ†é’Ÿå†…é‡å¤å‘é‚®ä»¶
   > 
   >     while True:
   >         now = datetime.datetime.now()
   > 
   >         for symbol, price_range in crypto_symbols.items():
   >             price = get_crypto_price(symbol)
   >             if price is None:
   >                 continue
   > 
   >             in_range = price_range["min_price"] <= price <= price_range["max_price"]
   > 
   >             if in_range:
   >                 hit_count[symbol] += 1
   >                 if hit_count[symbol] >= 15:
   >                     triggered.add(symbol)
   >             else:
   >                 hit_count[symbol] = 0  # ä¸€æ—¦è„±ç¦»åŒºé—´å°±æ¸…é›¶
   > 
   >         # æ•´ç‚¹/åŠç‚¹å¹¶ä¸”è§¦å‘å¸ç§éžç©ºï¼Œä¸”ä¸æ˜¯åˆšå‘è¿‡é‚®ä»¶
   >         if is_summary_time():
   >             current_minute = now.minute
   >             if triggered and current_minute != last_summary_minute:
   >                 body = "ä»¥ä¸‹å¸ç§åœ¨è¿‡åŽ»æ£€æµ‹ä¸­æ»¡è¶³ä»·æ ¼æ¡ä»¶ï¼š\n\n"
   >                 for symbol in triggered:
   >                     body += f"- {symbol}: å½“å‰ä»·æ ¼ä¸º {get_crypto_price(symbol)}ï¼Œè¶…è¿‡15æ¬¡åœ¨ç›®æ ‡èŒƒå›´å†…\n"
   >                 subject = f"ðŸ“ˆ åŠ å¯†è´§å¸ä»·æ ¼æé†’ï¼ˆ{now.strftime('%H:%M')}ï¼‰"
   >                 print(f"å½“å‰æ—¶é—´ï¼š{now.strftime('%H:%M')}")
   >                 print(f"é‚®ä»¶å†…å®¹ï¼š\n{body}")
   >                 send_mail(subject, body, to_email)
   >                 triggered.clear()
   >                 hit_count = {symbol: 0 for symbol in crypto_symbols}
   >                 last_summary_minute = current_minute
   > 
   >         time.sleep(2)  # æ¯10ç§’æ£€æµ‹ä¸€æ¬¡
   > 
   > # ä¸»å‡½æ•°å…¥å£
   > if __name__ == "__main__":
   >     monitor_crypto()
   > ```
   >

11. ç•ªèŒ„é’Ÿ

   > ç”¨æ³•ï¼šç”¨`pomodoro.command`æŽ§åˆ¶`pomodoro.py`
   >
   > 1. æå‰ç”¨Previewæ‰“å¼€ä¸€ä¸ªå›¾ç‰‡ï¼Œä¸”æ”¾åœ¨æ¡Œé¢ä¸Šï¼Œä¸èƒ½æœ€å°åŒ–
   >
   > 2. `pomodoro.py`
   >
   >    ```python
   >    # åŠŸèƒ½ï¼šç•ªèŒ„é’Ÿ + æœ—è¯» + åˆ‡æ¢å¹¶å…¨å± Preview
   >    import asyncio
   >    import subprocess
   >    import os
   >    from edge_tts import Communicate
   >    
   >    # ðŸ—£ï¸ æœ—è¯»æ–‡æœ¬å‡½æ•°
   >    async def speak(text):
   >        communicate = Communicate(text, voice="zh-CN-XiaoxiaoNeural")
   >        await communicate.save("output.mp3")
   >        os.system("afplay output.mp3")
   >    
   >    # ðŸ… åˆ‡æ¢å¹¶å…¨å± Preview
   >    def activate_and_fullscreen_preview():
   >        applescript = '''
   >        tell application "Preview"
   >            activate
   >        end tell
   >        delay 1
   >        tell application "System Events"
   >            keystroke "f" using {control down, command down}
   >        end tell
   >        '''
   >        subprocess.run(["osascript", "-e", applescript])
   >    
   >    # ðŸ” ä¸»å¾ªçŽ¯é€»è¾‘å°è£…æˆ async
   >    async def pomodoro_loop():
   >        try:
   >            while True:
   >                print("ðŸ… å¼€å§‹ä¸“æ³¨ï¼š25åˆ†é’Ÿ")
   >                await asyncio.sleep(10)
   >                # await asyncio.sleep(25 * 60)
   >                await speak("ä¼‘æ¯ä¸€ä¸‹å§")
   >                activate_and_fullscreen_preview()
   >    
   >                print("ðŸ˜Œ ä¼‘æ¯ä¸­ï¼š10åˆ†é’Ÿ")
   >                await asyncio.sleep(5)
   >                # await asyncio.sleep(10 * 60)
   >                await speak("å¼€å§‹å¹²æ´»å§")
   >                activate_and_fullscreen_preview()
   >        except asyncio.CancelledError:
   >            print("ç•ªèŒ„é’Ÿå·²è¢«ä¸­æ­¢ã€‚")
   >    
   >    # ðŸ‘‡ é¡¶å±‚äº‹ä»¶å¾ªçŽ¯å…¥å£
   >    if __name__ == "__main__":
   >        asyncio.run(pomodoro_loop())
   >    ```
   >
   > 3. `pomodoro.command`
   >
   >    ```bash
   >    #!/bin/bash
   >    
   >    LOCK_FILE="$HOME/.pomodoro.lock"
   >    SCRIPT_PATH="$HOME/Downloads/Pythonè„šæœ¬/pomodoro.py"
   >    
   >    # å¦‚æžœé”æ–‡ä»¶å­˜åœ¨ï¼Œè¯»å–å…¶ä¸­çš„ PID
   >    if [ -f "$LOCK_FILE" ]; then
   >        OLD_PID=$(cat "$LOCK_FILE")
   >    
   >        # æ£€æŸ¥è¯¥ PID æ˜¯å¦ä»åœ¨è¿è¡Œä¸”æ˜¯æˆ‘ä»¬è¿™ä¸ªè„šæœ¬
   >        if ps -p "$OLD_PID" > /dev/null && ps -p "$OLD_PID" -o args= | grep -q "$SCRIPT_PATH"; then
   >            # æ˜¯åœ¨è¿è¡Œä¸­ï¼Œå…³é—­å®ƒ
   >            kill "$OLD_PID"
   >            rm -f "$LOCK_FILE"
   >            osascript -e 'display notification "å…³é—­ç•ªèŒ„é’Ÿ" with title "æé†’åŠ©æ‰‹"'
   >            exit 0
   >        else
   >            # PID ä¸å­˜åœ¨æˆ–ä¸æ˜¯æˆ‘ä»¬çš„è„šæœ¬ï¼Œç§»é™¤é”æ–‡ä»¶
   >            rm -f "$LOCK_FILE"
   >        fi
   >    fi
   >    
   >    # å¯åŠ¨è„šæœ¬ï¼ˆåŽå°ï¼‰ï¼Œä¿å­˜ PID
   >    /opt/anaconda3/bin/python3 "$SCRIPT_PATH" >> "$HOME/Desktop/pomodoro.log" 2>&1 &
   >    NEW_PID=$!
   >    echo "$NEW_PID" > "$LOCK_FILE"
   >    osascript -e 'display notification "å¼€å¯ç•ªèŒ„é’Ÿ" with title "æé†’åŠ©æ‰‹"'
   >    ```
   >
   > 4. æŽˆæƒç»ˆç«¯Terminalæƒé™
   >
   >    > ç³»ç»Ÿåå¥½è®¾ç½® â†’ éšç§ä¸Žå®‰å…¨æ€§ â†’ è¾…åŠ©åŠŸèƒ½ â†’ æ·»åŠ ã€ç»ˆç«¯Terminalã€‘
   >
   > 

   